# ğŸ§¬ Cancer RAG â€” Conversational Oncology Research Assistant

A **Retrieval-Augmented Generation (RAG)** system designed to provide structured, context-grounded responses to cancer-related research queries using curated medical literature.

This version implements:

* ğŸŒ Streamlit Chat Interface
* ğŸ” Chroma Vector Database
* ğŸ§  Dual-Stage Retrieval (Small Embedding + Large Rerank)
* ğŸ¤– OpenAI GPT Model for Response Generation
* ğŸ’¬ Conversational Memory Support
* ğŸ” Environment-based API configuration

---

## ğŸš€ Project Overview

Cancer RAG is a conversational oncology research assistant that:

* Retrieves relevant cancer literature using semantic search
* Reranks results using a higher-quality embedding model
* Generates responses strictly grounded in retrieved documents
* Maintains conversational memory across turns
* Handles greetings and general small talk professionally
* Avoids hallucinations via strict prompt guardrails

This system is designed for **research and educational use only**.

---

## ğŸ—ï¸ Architecture

```
User (Browser)
        â†“
Streamlit Chat UI
        â†“
Chroma Vector Retrieval (Small Embedding)
        â†“
Top-5 Candidate Chunks
        â†“
Large Embedding Reranking (Similarity Scoring)
        â†“
Final Ordered Context
        â†“
OpenAI GPT Model
        â†“
Structured, Context-Grounded Response
```

---

## ğŸ› ï¸ Tech Stack

| Component       | Technology                                      |
| --------------- | ----------------------------------------------- |
| LLM             | OpenAI GPT (e.g., gpt-5-nano-2025-08-07)        |
| Retrieval Embed | sentence-transformers OR text-embedding-3-small |
| Rerank Embed    | text-embedding-3-large                          |
| Vector DB       | Chroma                                          |
| Framework       | LangChain                                       |
| UI              | Streamlit                                       |
| Similarity      | Cosine Similarity (NumPy)                       |
| Config          | dotenv (.env)                                   |

---

## ğŸ§  Retrieval Strategy

This project uses a **two-stage retrieval pipeline**:

### 1ï¸âƒ£ Fast Candidate Retrieval

* Query embedded using:

  * `sentence-transformers/all-MiniLM-L6-v2`
    **OR**
  * `text-embedding-3-small`
* Chroma retrieves top-5 semantically similar chunks.

### 2ï¸âƒ£ High-Quality Reranking

* Query embedded using `text-embedding-3-large`
* Each retrieved chunk embedded using `text-embedding-3-large`
* Cosine similarity computed
* Chunks reordered by semantic similarity

This approach improves precision while keeping retrieval efficient.

---

## ğŸ’¬ Conversational Memory

The assistant maintains chat history using Streamlit session state:

* Previous user and assistant messages are appended to the prompt.
* Context window is dynamically constructed.
* Enables multi-turn follow-up questions.

Example:

> User: What is chemotherapy?
> User: What are its side effects?

The second question uses prior conversation context.

---

## ğŸ¯ Prompt Guardrails

The assistant follows strict behavioral rules:

### âœ… General Conversation

* Responds naturally to greetings and small talk.
* Maintains professional customer-service tone.

### âœ… Cancer-Related Questions

* Answers ONLY using retrieved context.
* No hallucinations.
* Structured explanations.
* No personalized medical advice.
* Includes disclaimers where appropriate.

### ğŸš« Out-of-Scope Questions

If unrelated to cancer:

> "I can only assist with cancer-related questions."

---

## ğŸ“‚ Project Structure

```
Cancer_RAG/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ cancer_chroma_db/   (Persisted Vector Store)
â”‚
â””â”€â”€ .env
```

---

## âš™ï¸ Setup & Installation

### ğŸ”¹ 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Bandi-Saideva-Goud/Cancer_RAG.git
cd Cancer_RAG
```

---

### ğŸ”¹ 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
# OR
.venv\Scripts\activate      # Windows
```

---

### ğŸ”¹ 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### ğŸ”¹ 4ï¸âƒ£ Configure Environment Variables

Create `.env` file:

```
OPENAI_API_KEY=your_openai_api_key
EMBEDDING_MODEL=text-embedding-3-small
WEB_LINK='https://jascap.org/cancer-books-pdf/english-books/'
CHROMA_PATH='./cancer_chroma_db'
MAX_WORKERS=4
```

You may also set:

```
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

---

### ğŸ”¹ 5ï¸âƒ£ Run Application

```bash
python -m streamlit run app.py
```

Open in browser:

```
http://localhost:8501
```

---

## ğŸ§ª Example Use Cases

* Cancer treatment explanation research
* Rare cancer investigation queries
* Oncology literature contextual Q&A
* Multi-turn research discussions

---

## âš ï¸ Disclaimer

This system is intended for research and educational purposes only.

It does not provide medical advice, diagnosis, or treatment recommendations.

Always consult qualified healthcare professionals for medical decisions.

---

## ğŸ§  Future Improvements

* Streaming token responses
* Retrieval score visualization
* RAG evaluation metrics (Recall@k, MRR)
* Cross-encoder reranking
* Context compression
* Token window management
* Hallucination detection layer

---

## ğŸ‘¨â€ğŸ’» Author

**Bandi Saideva Goud**
Data Scientist | AI Engineer
Focused on LLM Systems, RAG Architectures, and Applied AI

---

# ğŸŒŸ Why This Project Matters

This project demonstrates:

* End-to-end conversational RAG system
* Multi-stage retrieval optimization
* Embedding-based reranking
* Memory-aware prompting
* Secure API-based LLM integration
* Practical healthcare AI application
* Production-oriented modular design

---
